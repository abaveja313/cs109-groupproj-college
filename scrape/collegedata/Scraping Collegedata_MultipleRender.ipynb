{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping collegedata.com with Qt Webkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import TIdatabase as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_ids=['Princeton', 'Harvard', 'Yale', 'Columbia', 'Stanford', 'UChicago', 'MIT', 'Duke', 'UPenn', 'CalTech', 'JohnsHopkins', 'Dartmouth', 'Northwestern', 'Brown', 'Cornell', 'Vanderbilt', 'WashU', 'Rice', 'NotreDame', 'UCB', 'Emory', 'Georgetown', 'CarnegieMellon', 'UCLA', 'USC']\n",
    "college_urls=[111, 444, 244, 399, 781, 327, 186, 1026, 67, 706, 1509, 403, 1803, 163, 787, 1562, 1720, 731, 1774, 1090, 1039, 1182, 204, 1093, 1138]\n",
    "college_id_dict=dict(zip(college_ids,college_urls))\n",
    "uni_list=['Princeton University', 'Harvard College', 'Yale University', 'Columbia University', 'Stanford University', 'University of Chicago', 'Massachusetts Institute of Technology', 'Duke University', 'University of Pennsylvania', 'California Institute of Technology', 'Johns Hopkins University', 'Dartmouth College', 'Northwestern University', 'Brown University', 'Cornell University', 'Vanderbilt University', 'Washington University in St. Louis', 'Rice University', 'University of Notre Dame', 'University of California, Berkeley', 'Emory Univesrity', 'Georgetown University', 'Carnegie Mellon University', 'University of California, Los Angeles', 'University of Southern California']\n",
    "uni_name_dict = dict(zip(uni_list, college_ids))\n",
    "uni_state=['NJ', 'MA', 'CT', 'NY', 'CA', 'IL', 'MA', 'NC', 'PA', 'CA', 'MD', 'NH', 'IL', 'RI', 'NY', 'TN', 'MO', 'TX', 'IN', 'CA', 'GA', 'DC', 'PA', 'CA', 'CA']\n",
    "states_dict={'Alabama': 'AL',\n",
    " 'Alaska': 'AK',\n",
    " 'American Samoa': 'AS',\n",
    " 'Arizona': 'AZ',\n",
    " 'Arkansas': 'AR',\n",
    " 'California': 'CA',\n",
    " 'Colorado': 'CO',\n",
    " 'Connecticut': 'CT',\n",
    " 'Delaware': 'DE',\n",
    " 'District of Columbia': 'DC',\n",
    " 'Florida': 'FL',\n",
    " 'Georgia': 'GA',\n",
    " 'Guam': 'GU',\n",
    " 'Hawaii': 'HI',\n",
    " 'Idaho': 'ID',\n",
    " 'Illinois': 'IL',\n",
    " 'Indiana': 'IN',\n",
    " 'Iowa': 'IA',\n",
    " 'Kansas': 'KS',\n",
    " 'Kentucky': 'KY',\n",
    " 'Louisiana': 'LA',\n",
    " 'Maine': 'ME',\n",
    " 'Maryland': 'MD',\n",
    " 'Massachusetts': 'MA',\n",
    " 'Michigan': 'MI',\n",
    " 'Minnesota': 'MN',\n",
    " 'Mississippi': 'MS',\n",
    " 'Missouri': 'MO',\n",
    " 'Montana': 'MT',\n",
    " 'National': 'NA',\n",
    " 'Nebraska': 'NE',\n",
    " 'Nevada': 'NV',\n",
    " 'New Hampshire': 'NH',\n",
    " 'New Jersey': 'NJ',\n",
    " 'New Mexico': 'NM',\n",
    " 'New York': 'NY',\n",
    " 'North Carolina': 'NC',\n",
    " 'North Dakota': 'ND',\n",
    " 'Northern Mariana Islands': 'MP',\n",
    " 'Ohio': 'OH',\n",
    " 'Oklahoma': 'OK',\n",
    " 'Oregon': 'OR',\n",
    " 'Pennsylvania': 'PA',\n",
    " 'Puerto Rico': 'PR',\n",
    " 'Rhode Island': 'RI',\n",
    " 'South Carolina': 'SC',\n",
    " 'South Dakota': 'SD',\n",
    " 'Tennessee': 'TN',\n",
    " 'Texas': 'TX',\n",
    " 'Utah': 'UT',\n",
    " 'Vermont': 'VT',\n",
    " 'Virgin Islands': 'VI',\n",
    " 'Virginia': 'VA',\n",
    " 'Washington': 'WA',\n",
    " 'West Virginia': 'WV',\n",
    " 'Wisconsin': 'WI',\n",
    " 'Wyoming': 'WY',\n",
    "  'Other': 'Other'}\n",
    "uni_state_dict = dict(zip(uni_list,uni_state))\n",
    "baseurl='http://www.collegedata.com/cs/admissions/'\n",
    "tracker_url='admissions_tracker_result.jhtml?schoolId='\n",
    "student_url='admissions_profile_view.jhtml?profileName='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Source: https://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/\n",
    "import sys\n",
    "from PyQt4.QtCore import *\n",
    "from PyQt4.QtGui import *\n",
    "from PyQt4.QtWebKit import *\n",
    "\n",
    "class Render(QWebPage):  \n",
    "    def __init__(self, urls):\n",
    "        self.app = QApplication(sys.argv)  \n",
    "        QWebPage.__init__(self)  \n",
    "        self.loadFinished.connect(self._loadFinished)  \n",
    "        self.urls = urls \n",
    "        self.profileList=set()\n",
    "        self.crawl()  \n",
    "        self.app.exec_()  \n",
    "      \n",
    "    def crawl(self):  \n",
    "        if self.urls:  \n",
    "            url = self.urls.pop(0)    \n",
    "            self.mainFrame().load(QUrl(url))  \n",
    "        else:  \n",
    "            self.app.quit()  \n",
    "        \n",
    "    def _loadFinished(self, result): \n",
    "        frame = self.mainFrame()  \n",
    "        url = str(frame.url().toString())  \n",
    "        html = frame.toHtml()  \n",
    "        self.scrape(url, html)\n",
    "        self.crawl()\n",
    "    \n",
    "    def scrape(self,url, html):\n",
    "        soup = BeautifulSoup(str(html.toAscii()),'html.parser')     \n",
    "        profiles=soup.find_all(\"a\",href=re.compile(r\"enterProfileByName\"))\n",
    "        for p in profiles:\n",
    "            self.profileList.add(p.get(\"href\").split(\"'\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to try out for 1 university and 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#urls=[]\n",
    "#schoolid=111\n",
    "#schoolurl=baseurl+tracker_url+str(schoolid)+'&classYear='\n",
    "#for year in range(2009,2011):\n",
    "#    urls.append(schoolurl+str(year))\n",
    "#r=Render(urls)\n",
    "#print len(r.profileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to try out for all universities and years 2009-2019. This takes about 55 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found  5020 students\n",
      "CPU times: user 21min 40s, sys: 3min 8s, total: 24min 48s\n",
      "Wall time: 53min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "urls=[]\n",
    "for school in college_id_dict:\n",
    "    schoolurl=baseurl+tracker_url+str(college_id_dict[school])+'&classYear='\n",
    "    for year in range(2009,2020):\n",
    "        urls.append(schoolurl+str(year))\n",
    "r=Render(urls)\n",
    "print 'We found ', len(r.profileList), 'students'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genderdict = {'Male': -1, 'Female': 1}\n",
    "highschooldict = {'Public': -1, 'Private': 1, 'Parochial': 1, 'Home-Schooled': 1}\n",
    "minoritylist = ['african', 'hispanic', 'latin','indian', 'native', 'black', 'mexican']\n",
    "nonminoritylist = ['white', 'caucasian', 'asian', 'european', 'chinese', 'hebrew']\n",
    "otherminorities=set()\n",
    "sats=[1600, 1560, 1510, 1460, 1420, 1380, 1340, 1300, 1260, 1220, 1190, 1150, 1110, 1070, 1030, 990, 950, 910, 870, \n",
    "      830, 790, 740, 690, 640, 590, 530]\n",
    "act2satdict=dict(zip(range(11,37),sats))\n",
    "booleandict={'': -1, 'X': 1}\n",
    "statusdict={'Will Attend': 1, 'Accepted': 1, 'Applied': 0, 'Deferred': -1, 'Denied': -1, 'Not Applied': 0, 'Wait-Listed': 1, 'Withdrawn': 0, '': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFromDict(dictionary,text):\n",
    "    if dictionary.has_key(text):\n",
    "        return dictionary[text]\n",
    "    else:\n",
    "        return 0\n",
    "def isMinority(text):\n",
    "    for m in minoritylist:\n",
    "        if m in text:\n",
    "            return 1\n",
    "    for m in nonminoritylist:\n",
    "        if m in text:\n",
    "            return -1\n",
    "    otherminorities.add(text)\n",
    "    return 0\n",
    "def getScores(scores,fun):\n",
    "    scores = [s.get_text().strip() for s in scores]\n",
    "    while '' in scores:\n",
    "        scores.remove('')\n",
    "    if len(scores)>0:\n",
    "        scores=[int(s) for s in scores]\n",
    "        return fun(scores), len(scores)\n",
    "    else:\n",
    "        return None, 0\n",
    "def getAdmissionTestScore(doc):\n",
    "    satCRM,dummy = getScores(doc[0:2],sum)\n",
    "    satW,dummy = getScores([doc[2]],np.max)\n",
    "    act,dummy = getScores([doc[4]],np.max)\n",
    "    if act == None:\n",
    "        return (satCRM+satW)\n",
    "    elif satCRM==None:\n",
    "        if satW==None:\n",
    "            print \"Warning: no SAT writing score\"\n",
    "        return act2satdict[act]+satW\n",
    "    else:\n",
    "        return (max(act2satdict[act],satCRM)+satW)\n",
    "def getCanAfford(text):\n",
    "    if 'Yes' in text:\n",
    "        return -1\n",
    "    elif 'No' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_student = ['classrank', 'admissionstest','AP','averageAP','SATsubject', 'GPA', 'GPA_w', 'program','schooltype',\n",
    "            'intendedgradyear', 'addInfo', 'canAfford', 'female', 'MinorityGender','MinorityRace','international',\n",
    "           'firstinfamily','sports','artist', 'workexp']\n",
    "columns_uni = ['collegeID','earlyAppl','visited','alumni', 'outofstate', 'acceptStatus','acceptProb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getColumnValues(soup):\n",
    "    values=dict(zip(columns_student,[None for i in range(len(columns_student))]))\n",
    "    applications=[]\n",
    "    # We start with the general information box at the top which includes class year, gender and ethnicity\n",
    "    doc= soup.find(\"div\",{\"class\": \"general\"})\n",
    "    values['intendedgradyear'] = int(re.findall(r'\\d{4}',doc.find(\"h1\").get_text().split('Class of')[-1])[0]) # CLASS YEAR\n",
    "    doc = doc.find_all(\"span\")\n",
    "    values['female']= getFromDict(genderdict,doc[0].get_text().strip()) # GENDER\n",
    "    values['MinorityGender']= 1 if values['female']==0 else -1\n",
    "    values['MinorityRace'] = isMinority(doc[1].get_text().strip().lower()) # MINORITY RACE\n",
    "    values['program'] = doc[2].get_text().strip() # PROGRAM\n",
    "    # Now we look at the academics box which includes GPA and high school info\n",
    "    doc = soup.find(\"div\", {\"class\": \"academicswrap\"}).find_all(\"span\")\n",
    "    values['schooltype']=getFromDict(highschooldict,doc[0].get_text().strip()) # SCHOOL TYPE\n",
    "    state=states_dict[doc[1].get_text().strip()] # STATE OF STUDENT\n",
    "    values['international'] = 1 if state=='Other' else -1\n",
    "    values['GPA'] = float(doc[3].get_text()) # unweighted GPA\n",
    "    values['GPA_w'] = float(doc[4].get_text()) if doc[4].get_text().strip()!='' else None # Weighted GPA\n",
    "    # Next, we go to the test score box which includes SAT, ACT and AP info\n",
    "    values['admissionstest'] = getAdmissionTestScore(soup.find(\"div\", {\"class\": \"testscorewrap\"}).find_all(\"td\")) #Admissions test\n",
    "    values['SATsubject'] = len(soup.find(\"caption\",text=\"SAT Subject Test Scores\").next_sibling.next_sibling.find_all(\"tr\")) # SAT SUBJECT\n",
    "    ap_num = len(soup.find(\"caption\",text=\"AP Examinations\").next_sibling.next_sibling.find_all(\"tr\"))\n",
    "    values['AP']=ap_num #AP\n",
    "    if ap_num>0:\n",
    "        doc = soup.find(\"caption\",text=\"AP Examinations\").next_sibling.next_sibling.find_all(\"td\")\n",
    "        values['averageAP'],values['AP']= getScores(doc,np.mean) # AVERAGE AP\n",
    "    doc = soup.find_all(\"div\", {\"class\": \"word\"})\n",
    "    doc = [d.get_text().strip() for d in doc]  \n",
    "    values['addInfo']= doc[0]+doc[1]+doc[2] # Additional info\n",
    "    # Next: the colleges applied to and the admission results for the admissions table\n",
    "    doc = soup.find(\"table\", {\"class\": \"collchoice\"})\n",
    "    collegelist = doc.find(\"tbody\").find_all(\"tr\")\n",
    "    for c in collegelist:\n",
    "        uni = c.find(\"th\").find(\"span\").get_text().strip()\n",
    "        if uni in uni_list:\n",
    "            unirow = dict(zip(columns_uni,[None for i in range(len(columns_uni))]))\n",
    "            unirow['collegeID']=uni_name_dict[uni]\n",
    "            doc=c.find_all(\"td\", {\"class\": \"center\"})\n",
    "            unirow['earlyAppl']=booleandict[doc[0].get_text().strip()] # Early Admission\n",
    "            unirow['alumni']=booleandict[doc[1].get_text().strip()] # Alumni/Legacy\n",
    "            if values['sports']==None or values['sports']==0: \n",
    "                values['sports']=booleandict[doc[2].get_text().strip()] # Athlete\n",
    "            doc = doc[2].next_sibling.find_next(\"span\")\n",
    "            unirow['acceptStatus']=statusdict[doc.get_text().strip()] # Admission status\n",
    "            if values['canAfford']==None or values['canAfford']==0:\n",
    "                values['canAfford']=getCanAfford(doc.find_next(\"span\").get_text().strip())\n",
    "            unirow['outofstate']= -1 if state==uni_state_dict[uni] else 1\n",
    "            applications.append(unirow)\n",
    "    return values, applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if ('students' in locals()): \n",
    "    students.cleanup()\n",
    "    del students\n",
    "if ('applForm' in locals()): del applForm\n",
    "students=ti.Student()\n",
    "colleges = ti.College()\n",
    "applForm = ti.ApplForm()\n",
    "for p in r.profileList:\n",
    "    profile_url=baseurl+student_url+p\n",
    "    soup=BeautifulSoup(requests.get(profile_url).text,'html.parser')\n",
    "    newrow, applications = getColumnValues(soup)\n",
    "    studentID=students.insert(newrow)\n",
    "    for app in applications:\n",
    "        app['studentID']=studentID[0]\n",
    "    applForm.insert(applications)\n",
    "students.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applForm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students.save('collegedata_students.csv')\n",
    "applForm.save('collegedata_applications.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
