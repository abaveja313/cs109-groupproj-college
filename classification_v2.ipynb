{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TIdatabase as ti\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from matplotlib import rcParams\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>studentID</th>\n",
       "      <th>classrank</th>\n",
       "      <th>admissionstest</th>\n",
       "      <th>AP</th>\n",
       "      <th>averageAP</th>\n",
       "      <th>SATsubject</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GPA_w</th>\n",
       "      <th>program</th>\n",
       "      <th>...</th>\n",
       "      <th>alumni</th>\n",
       "      <th>outofstate</th>\n",
       "      <th>acceptStatus</th>\n",
       "      <th>acceptProb</th>\n",
       "      <th>name</th>\n",
       "      <th>acceptrate</th>\n",
       "      <th>size</th>\n",
       "      <th>public</th>\n",
       "      <th>finAidPct</th>\n",
       "      <th>instatePct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PWY05BUB4I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>7</td>\n",
       "      <td>1.067339</td>\n",
       "      <td>0.324272</td>\n",
       "      <td>-0.187110</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>Biomedical engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.151</td>\n",
       "      <td>6621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3UVDFVI9Z0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293054</td>\n",
       "      <td>7</td>\n",
       "      <td>0.660575</td>\n",
       "      <td>-0.440777</td>\n",
       "      <td>0.493474</td>\n",
       "      <td>0.398944</td>\n",
       "      <td>Classics</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.151</td>\n",
       "      <td>6621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BCCBHJUP0M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293054</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.324272</td>\n",
       "      <td>0.396247</td>\n",
       "      <td>-1.035273</td>\n",
       "      <td>Biological Science</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.151</td>\n",
       "      <td>6621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WZFPWHSQMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.387878</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863957</td>\n",
       "      <td>1.089320</td>\n",
       "      <td>0.104569</td>\n",
       "      <td>-0.383356</td>\n",
       "      <td>Physics</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.151</td>\n",
       "      <td>6621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5W1JNQA7G0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408299</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.356334</td>\n",
       "      <td>-0.440777</td>\n",
       "      <td>0.542087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.151</td>\n",
       "      <td>6621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   studentID  classrank  admissionstest  AP  averageAP  \\\n",
       "0           0  PWY05BUB4I        NaN        0.926899   7   1.067339   \n",
       "1           1  3UVDFVI9Z0        NaN        0.293054   7   0.660575   \n",
       "2           2  BCCBHJUP0M        NaN        0.293054   0        NaN   \n",
       "3           3  WZFPWHSQMS        NaN        1.387878   7   0.863957   \n",
       "4           4  5W1JNQA7G0        NaN        0.408299   1  -0.356334   \n",
       "\n",
       "   SATsubject       GPA     GPA_w                 program     ...      alumni  \\\n",
       "0    0.324272 -0.187110  0.059947  Biomedical engineering     ...           0   \n",
       "1   -0.440777  0.493474  0.398944                Classics     ...           0   \n",
       "2    0.324272  0.396247 -1.035273      Biological Science     ...           0   \n",
       "3    1.089320  0.104569 -0.383356                 Physics     ...           0   \n",
       "4   -0.440777  0.542087       NaN                     NaN     ...           0   \n",
       "\n",
       "   outofstate acceptStatus  acceptProb  name  acceptrate  size  public  \\\n",
       "0           0            1         NaN  Rice       0.151  6621       0   \n",
       "1           1            1         NaN  Rice       0.151  6621       0   \n",
       "2           1            0         NaN  Rice       0.151  6621       0   \n",
       "3           1            0         NaN  Rice       0.151  6621       0   \n",
       "4           1            1         NaN  Rice       0.151  6621       0   \n",
       "\n",
       "   finAidPct  instatePct  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"collegedata_normalized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check for NaNs. The code below shows that 23% of all entries are null. This is way too high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.225931657684\n"
     ]
    }
   ],
   "source": [
    "x = df.isnull().sum(axis=1).tolist()\n",
    "y = float(sum(x)) / (df.shape[0]*df.shape[1])\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decrease the proportion of NaNs, we get rid of columns which are almost all null. From the `df.head()` above, we see that either a column is almost all null, or it is almost all non-null. Therefore the 23% above is probably driven mainly by columns that are basically all null. \n",
    "\n",
    "So we remove any column that has 50% or more null values. This takes out any predictors that would have been useless anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classrank', 'canAfford', 'firstinfamily', 'artist', 'workexp', 'visited', 'acceptProb']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = []\n",
    "for i in df.columns:\n",
    "    if 1.0* df[i].isnull().sum() / len(df[i]) >= 0.5:\n",
    "        cols_to_drop.append(i)\n",
    "print cols_to_drop\n",
    "dfr = df.drop(cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0371840368572\n"
     ]
    }
   ],
   "source": [
    "x = dfr.isnull().sum(axis=1).tolist()\n",
    "y = float(sum(x)) / (dfr.shape[0]*dfr.shape[1])\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have only 4% null values. Good! The next step is to choose which columns we want to use to predict. Obviously columns like `studentID`, while crucial, are not actually predictors. Also, we remove weighted GPA in favour of GPA, as we have already normalised everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'studentID', u'admissionstest', u'AP', u'averageAP',\n",
      "       u'SATsubject', u'GPA', u'GPA_w', u'program', u'schooltype',\n",
      "       u'intendedgradyear', u'addInfo', u'female', u'MinorityGender',\n",
      "       u'MinorityRace', u'international', u'sports', u'collegeID',\n",
      "       u'earlyAppl', u'alumni', u'outofstate', u'acceptStatus', u'name',\n",
      "       u'acceptrate', u'size', u'public', u'finAidPct', u'instatePct'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print dfr.columns\n",
    "predictor_cols = [\"admissionstest\",\"AP\",\"averageAP\",\"SATsubject\",\"GPA\",\"schooltype\",\"intendedgradyear\",\"female\",\"MinorityRace\",\"international\",\"sports\",\"earlyAppl\",\"alumni\",\"outofstate\",\"acceptrate\",\"size\",\"public\",\"finAidPct\",\"instatePct\"]\n",
    "dfpredict = dfr[predictor_cols]\n",
    "dfresponse = dfr[\"acceptStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates that if we remove all the rows with ANY nulls in it, we reduce our dataset from 16k to 12k. This reduces our dataset too much. So we will have to impute the missing values. We initially tried to do this using the `mice` package in R, but there does not seem to be an equivalent in Python. Since the % of nulls is just 4%, it shouldn't matter too much what method we use. Since some of the variables are factor, not numerical, we can't use mean or media. We are looking into KNN imputation, but for the time being, just use most common value. As stated, it shouldn't matter too much what method we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13200, 19)\n",
      "(16062, 19)\n"
     ]
    }
   ],
   "source": [
    "print dfpredict.dropna(axis=0,how=\"any\").shape\n",
    "print dfpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16062, 19), (16062,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = Imputer(missing_values=\"NaN\", strategy=\"most_frequent\", axis=1)\n",
    "imp.fit(dfpredict)\n",
    "X = imp.transform(dfpredict)\n",
    "y = dfresponse\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
