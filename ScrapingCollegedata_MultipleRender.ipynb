{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping collegedata.com with Qt Webkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import TIdatabase as ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collegedata.com is a website where we can find a lot of data in almost standardized form. The website has a page for each university, containing a list of student profiles that applied there. An example of such a page can be found [here](http://www.collegedata.com/cs/admissions/admissions_tracker_result.jhtml?schoolId=444&classYear=2020). The webiste also has a [page](http://www.collegedata.com/cs/admissions/admissions_profile_view.jhtml?profileName=FutureMD98) for each student profile. These pages contain the information we need: where the student applied and whether they got in, personal information like gender and race and academic information like test scores. Our scraping process consists of two parts. First, we visit the pages for each university in our list to get a list of student profile names. In part two, we visit each student page, scrape the information and add it to a dataframe.\n",
    "\n",
    "The URL of a university page is as follows:\n",
    "http://www.collegedata.com/cs/admissions/admissions_tracker_result.jhtml?schoolId=444&classYear=2020  \n",
    "Every university has an ID number. Since we are considering a list of 25 fixed universities, we will hardcode these ID's in a dictionary. The second parameter for the link is the graduation year of the applicants. \n",
    "\n",
    "The URL of a student profile page is as follows:\n",
    "http://www.collegedata.com/cs/admissions/admissions_profile_view.jhtml?profileName=FutureMD98  \n",
    "Once we have a list of profile names from part 1, we can easily create each of these urls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting a list of student profile names\n",
    "\n",
    "Below, we define some dictionaries and list with information on the universities.\n",
    "- `college_ids` is a list of university names that serve as university ID in our university dataframe (defined in `TIdatabase.py`).\n",
    "- `college_urls` is the list of numeric university ID's used by collegedata.com, in the same order as in `college_ids`.\n",
    "- `college_id_dict` is a dictionary with the university names as key and the numeric ID's as value and can be used to create the collegedata.com urls.  \n",
    "\n",
    "Finally, we define the base urls for the pages that we want to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_ids=['Princeton', 'Harvard', 'Yale', 'Columbia', 'Stanford', 'UChicago', 'MIT', 'Duke', 'UPenn', 'CalTech', 'JohnsHopkins', 'Dartmouth', 'Northwestern', 'Brown', 'Cornell', 'Vanderbilt', 'WashU', 'Rice', 'NotreDame', 'UCB', 'Emory', 'Georgetown', 'CarnegieMellon', 'UCLA', 'USC']\n",
    "college_urls=[111, 444, 244, 399, 781, 327, 186, 1026, 67, 706, 1509, 403, 1803, 163, 787, 1562, 1720, 731, 1774, 1090, 1039, 1182, 204, 1093, 1138]\n",
    "college_id_dict=dict(zip(college_ids,college_urls))\n",
    "baseurl='http://www.collegedata.com/cs/admissions/'\n",
    "tracker_url='admissions_tracker_result.jhtml?schoolId='\n",
    "student_url='admissions_profile_view.jhtml?profileName='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the webpage of a university on collegedata.com requires a special approach, as the data itself is loaded by Javascript and therefore cannot simply be found in the html code that we get when using `requests`.  The following code has been found in a [blogpost](https://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/) and helps to load the page before we scrape it. When creating an object of the class `Render`, we give a list of urls as parameter. The object then uses webkit to process the Javascript on each webpage in the list before accessing the resulting html code. We embed the function `scrape` which immediately obtains the list of profilenames from each webpage. Each profilename in the code is part of the `href` in a `<a>` tag as follows:\n",
    "\n",
    "`<a style=\"...\" rel=\"...\" href=\"javascript:enterProfileByName('rorygilmore')\"></a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Source: https://webscraping.com/blog/Scraping-multiple-JavaScript-webpages-with-webkit/\n",
    "import sys\n",
    "from PyQt4.QtCore import *\n",
    "from PyQt4.QtGui import *\n",
    "from PyQt4.QtWebKit import *\n",
    "\n",
    "class Render(QWebPage):  \n",
    "    def __init__(self, urls):\n",
    "        self.app = QApplication(sys.argv)  \n",
    "        QWebPage.__init__(self)  \n",
    "        self.loadFinished.connect(self._loadFinished)  \n",
    "        self.urls = urls \n",
    "        self.profileList=set()\n",
    "        self.crawl()  \n",
    "        self.app.exec_()  \n",
    "      \n",
    "    def crawl(self):  \n",
    "        if self.urls:  \n",
    "            url = self.urls.pop(0)    \n",
    "            self.mainFrame().load(QUrl(url))  \n",
    "        else:  \n",
    "            self.app.quit()  \n",
    "        \n",
    "    def _loadFinished(self, result): \n",
    "        frame = self.mainFrame()  \n",
    "        url = str(frame.url().toString())  \n",
    "        html = frame.toHtml()  \n",
    "        self.scrape(url, html)\n",
    "        self.crawl()\n",
    "    \n",
    "    # Once we have the html code with processed Javascript, we can parse it to find the profile names\n",
    "    def scrape(self,url, html):\n",
    "        soup = BeautifulSoup(str(html.toAscii()),'html.parser')   # we create a beautiful soup object   \n",
    "        profiles=soup.find_all(\"a\",href=re.compile(r\"enterProfileByName\")) # find all <a> tags that contain the string 'enterProfileByName'\n",
    "        for p in profiles:\n",
    "            self.profileList.add(p.get(\"href\").split(\"'\")[1]) #the profile name is between apostrophe's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have to do to obtain our list of profile names is to create a list of all university page urls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell finds the profile names for all 25 universities and years 2009-2019. This code takes about 55 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found  5028 students\n",
      "CPU times: user 22min 18s, sys: 4min 20s, total: 26min 39s\n",
      "Wall time: 38min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "urls=[]\n",
    "for school in college_id_dict:\n",
    "    schoolurl=baseurl+tracker_url+str(college_id_dict[school])+'&classYear='\n",
    "    for year in range(2009,2020):\n",
    "        urls.append(schoolurl+str(year))\n",
    "r=Render(urls)\n",
    "print 'We found ', len(r.profileList), 'students'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of these profile names turn out to be useless as their webpages are empty so we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found  5026 students\n"
     ]
    }
   ],
   "source": [
    "# these are bad profiles without any information\n",
    "r.profileList.remove('orangecat')\n",
    "r.profileList.remove('j7Wa4')\n",
    "r.profileList.remove('EDz3k')\n",
    "print 'We found ', len(r.profileList), 'students'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scraping student profile pages\n",
    "\n",
    "Now that we have a list of profile names (`r.profileList`), we can easily create the urls of each student profile page. This time, we can find our data directly in the html so we don't need any Javascript processing. \n",
    "\n",
    "We start by defining a series of dictionaries that we will need to convert strings we find in the html code to the  information we need. For a full description of the dataframe columns and types, we refer to `TIdatabase.py` and this [Google doc](https://docs.google.com/spreadsheets/d/1dm73Vmov8bhNoVRUtyg6TU-IgE7DPDVlukMkvnaCqAg/edit#gid=0&vpid=A1).\n",
    "\n",
    "We will create two dataframes. One contains all the information for each individual student. The other combines student ID's and university ID's and contains the information of a that student's application to that university. The dataframe columns can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_student = ['classrank', 'admissionstest','AP','averageAP','SATsubject', 'GPA', 'GPA_w', 'program','schooltype',\n",
    "            'intendedgradyear', 'addInfo', 'canAfford', 'female', 'MinorityGender','MinorityRace','international',\n",
    "           'firstinfamily','sports','artist', 'workexp']\n",
    "columns_uni = ['collegeID','earlyAppl','visited','alumni', 'outofstate', 'acceptStatus','acceptProb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For indicator columns, we will assign -1 for False, 1 for True and 0 when the information is unavailable or undecisive. \n",
    "\n",
    "We use [this](https://www.act.org/solutions/college-career-readiness/compare-act-sat/) webpage to convert ACT composite scores to SAT critical reading and math (CR+M) scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indicators for gender, corresponding to dataframe column 'female':\n",
    "genderdict = {'Male': -1, 'Female': 1} \n",
    "#Indicator for the type of high school for the dataframe column 'schooltype':\n",
    "highschooldict = {'Public': -1, 'Private': 1, 'Parochial': 1, 'Home-Schooled': 1} \n",
    "# A list of words we associate with underrepresented minority races for the dataframe column 'MinorityRace'\n",
    "minoritylist = ['african', 'hispanic', 'latin','indian', 'native', 'black', 'mexican','puerto','alaska','hawai','pacific island']\n",
    "# A list of SAT scores from https://www.act.org/solutions/college-career-readiness/compare-act-sat/ corresponding to ACT composite scores between 36 and 11\n",
    "sats=[1600, 1560, 1510, 1460, 1420, 1380, 1340, 1300, 1260, 1220, 1190, 1150, 1110, 1070, 1030, 990, 950, 910, 870, \n",
    "      830, 790, 740, 690, 640, 590, 530]\n",
    "# A dictionary to translate an ACT composite score to an SAT CR+M score.\n",
    "act2satdict=dict(zip(range(36,10,-1),sats))\n",
    "# General indicator for boolean columns in the webpage. For example the column 'Athlete' of 'Alumni'\n",
    "booleandict={'': -1, 'X': 1}\n",
    "# Indicators for the admission status corresponding to dataframe column 'acceptStatus'\n",
    "statusdict={'Will Attend': 1, 'Accepted': 1, 'Applied': 0, 'Deferred': -1, 'Denied': -1, 'Not Applied': 0, 'Wait-Listed': -1, 'Withdrawn': 0, 'Pending': -1}\n",
    "# List of university names as used on collegedata.com\n",
    "uni_list=['Princeton University', 'Harvard College', 'Yale University', 'Columbia University', 'Stanford University', 'University of Chicago', 'Massachusetts Institute of Technology', 'Duke University', 'University of Pennsylvania', 'California Institute of Technology', 'Johns Hopkins University', 'Dartmouth College', 'Northwestern University', 'Brown University', 'Cornell University', 'Vanderbilt University', 'Washington University in St. Louis', 'Rice University', 'University of Notre Dame', 'University of California, Berkeley', 'Emory University', 'Georgetown University', 'Carnegie Mellon University', 'University of California, Los Angeles', 'University of Southern California']\n",
    "# Dictionary to translate the university name used on collegedata.com to the university name used in our dataframe\n",
    "uni_name_dict = dict(zip(uni_list, college_ids))\n",
    "# List of states for each university\n",
    "uni_state=['NJ', 'MA', 'CT', 'NY', 'CA', 'IL', 'MA', 'NC', 'PA', 'CA', 'MD', 'NH', 'IL', 'RI', 'NY', 'TN', 'MO', 'TX', 'IN', 'CA', 'GA', 'DC', 'PA', 'CA', 'CA']\n",
    "# Dictionary get the state of a university\n",
    "uni_state_dict = dict(zip(uni_list,uni_state))\n",
    "# Dictionary to translate a state to its abbreviation \n",
    "states_dict={'Alabama': 'AL',\n",
    " 'Alaska': 'AK',\n",
    " 'American Samoa': 'AS',\n",
    " 'Arizona': 'AZ',\n",
    " 'Arkansas': 'AR',\n",
    " 'California': 'CA',\n",
    " 'Colorado': 'CO',\n",
    " 'Connecticut': 'CT',\n",
    " 'Delaware': 'DE',\n",
    " 'District of Columbia': 'DC',\n",
    " 'Florida': 'FL',\n",
    " 'Georgia': 'GA',\n",
    " 'Guam': 'GU',\n",
    " 'Hawaii': 'HI',\n",
    " 'Idaho': 'ID',\n",
    " 'Illinois': 'IL',\n",
    " 'Indiana': 'IN',\n",
    " 'Iowa': 'IA',\n",
    " 'Kansas': 'KS',\n",
    " 'Kentucky': 'KY',\n",
    " 'Louisiana': 'LA',\n",
    " 'Maine': 'ME',\n",
    " 'Maryland': 'MD',\n",
    " 'Massachusetts': 'MA',\n",
    " 'Michigan': 'MI',\n",
    " 'Minnesota': 'MN',\n",
    " 'Mississippi': 'MS',\n",
    " 'Missouri': 'MO',\n",
    " 'Montana': 'MT',\n",
    " 'National': 'NA',\n",
    " 'Nebraska': 'NE',\n",
    " 'Nevada': 'NV',\n",
    " 'New Hampshire': 'NH',\n",
    " 'New Jersey': 'NJ',\n",
    " 'New Mexico': 'NM',\n",
    " 'New York': 'NY',\n",
    " 'North Carolina': 'NC',\n",
    " 'North Dakota': 'ND',\n",
    " 'Northern Mariana Islands': 'MP',\n",
    " 'Ohio': 'OH',\n",
    " 'Oklahoma': 'OK',\n",
    " 'Oregon': 'OR',\n",
    " 'Pennsylvania': 'PA',\n",
    " 'Puerto Rico': 'PR',\n",
    " 'Rhode Island': 'RI',\n",
    " 'South Carolina': 'SC',\n",
    " 'South Dakota': 'SD',\n",
    " 'Tennessee': 'TN',\n",
    " 'Texas': 'TX',\n",
    " 'Utah': 'UT',\n",
    " 'Vermont': 'VT',\n",
    " 'Virgin Islands': 'VI',\n",
    " 'Virginia': 'VA',\n",
    " 'Washington': 'WA',\n",
    " 'West Virginia': 'WV',\n",
    " 'Wisconsin': 'WI',\n",
    " 'Wyoming': 'WY',\n",
    "  'Other': 'Other'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some functions to help convert the html strings to the right form for our dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getFromDict: general function that looks up a key in a dictionary and returns the value if available and 0 if not available\n",
    "#              input:      dictionary = any dictionary for indicators\n",
    "#                          text = key to look up in dictonary\n",
    "#              output:     if the dictionary has text as input, output = dictionary[text], else output=0\n",
    "def getFromDict(dictionary,text):\n",
    "    if dictionary.has_key(text):\n",
    "        return dictionary[text]\n",
    "    else:\n",
    "        return 0\n",
    "# isMinority: check if a string contains one of the words associated with minorities\n",
    "#              input:      text = user-supplied string describing a race\n",
    "#              output:     output = 1 if the race is considered a minority, else output = -1 \n",
    "def isMinority(text):\n",
    "    for m in minoritylist:\n",
    "        if m in text:\n",
    "            return 1\n",
    "    return -1\n",
    "# getScores: obtain a metric from scores, given a list of html strings containing scores \n",
    "#              input:      scores = list of html strings containing scores\n",
    "#                          fun = function to apply to the scores\n",
    "#              output:     metric obtained by applying fun to the list of numerical scores\n",
    "#                          and the number of valid scores found in the list\n",
    "def getScores(scores,fun):\n",
    "    scores = [s.get_text().strip() for s in scores] # clean the strings\n",
    "    while '' in scores: \n",
    "        scores.remove('') # remove all empty strings\n",
    "    if len(scores)>0:\n",
    "        scores=[int(s) for s in scores] # create list of actual numerical scores\n",
    "        return fun(scores), len(scores)\n",
    "    else:\n",
    "        return None, 0\n",
    "# getAdmissionTestScore: obtain one single admission test score, given SAT and ACT scores\n",
    "#              input:      doc = list of html strings containing the SAT scores (CR, M and W) and the ACT score\n",
    "#              output:     a single score derived from the combination of available admission test scores\n",
    "def getAdmissionTestScore(doc):\n",
    "    satCRM,dummy = getScores(doc[0:2],sum) # Get the sum of the SAT CR and M scores\n",
    "    satW,dummy = getScores([doc[2]],np.max) # Get the SAT W score\n",
    "    act,dummy = getScores([doc[4]],np.max) # Get the ACT score\n",
    "    if act == None: # If no ACT score available, we just use the total SAT score\n",
    "        return (satCRM+satW)\n",
    "    elif satCRM==None: # if no SAT CR + M score, we need to replace it with the ACT score\n",
    "        if satW==None: # if also no SAT W score available, there is a problem ( but this is never the case )\n",
    "            print \"Warning: no SAT writing score\"\n",
    "        return act2satdict[act]+satW # Convert ACT to an SAT score and combine with the SAT W score\n",
    "    else: # if all scores available, we use the maximum of the translated ACT score and SAT CR+M score\n",
    "        return (max(act2satdict[act],satCRM)+satW)\n",
    "# getCanAfford: detect the indicator 'canAfford'\n",
    "#              input:      text = string from the html that indicates whether a student applied for financial support\n",
    "#              output:     output =1 if the student can probably afford tuition, output = -1 if the student applied for financial support, output =0 if information unavailable\n",
    "def getCanAfford(text):\n",
    "    if 'Yes' in text:\n",
    "        return -1\n",
    "    elif 'No' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# removePunct: general function to clean up string-based columns\n",
    "#              input:      text = string to clean\n",
    "#              output:     cleaned string\n",
    "def removePunct(text):\n",
    "    text = re.sub(r'([^\\s\\w]|_)+',\" \",text)\n",
    "    return re.sub('\\s+',' ',text).encode('latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the function that does all the work. Given a beautiful soup object, we create two things. One is a dictionary that corresponds to a row in the Students dataframe and the other is a list of dictionaries, one for every application from that student to one of the universities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getColumnValues(soup):\n",
    "    # initialize the dictionary and list\n",
    "    values=dict(zip(columns_student,[None for i in range(len(columns_student))]))\n",
    "    applications=[]\n",
    "    # We start with the general information box at the top which includes class year, gender and ethnicity\n",
    "    doc= soup.find(\"div\",{\"class\": \"general\"})\n",
    "    values['intendedgradyear'] = int(re.findall(r'\\d{4}',doc.find(\"h1\").get_text().split('Class of')[-1])[0]) # CLASS YEAR\n",
    "    doc = doc.find_all(\"span\")\n",
    "    values['female']= getFromDict(genderdict,doc[0].get_text().strip()) # GENDER\n",
    "    values['MinorityGender']= 1 if values['female']==0 else -1 # Minority gender if no gender found\n",
    "    values['MinorityRace'] = isMinority(doc[1].get_text().strip().lower()) # MINORITY RACE\n",
    "    values['program'] = removePunct(doc[2].get_text().strip()) # PROGRAM\n",
    "    # Now we look at the academics box which includes GPA and high school info\n",
    "    doc = soup.find(\"div\", {\"class\": \"academicswrap\"}).find_all(\"span\")\n",
    "    values['schooltype']=getFromDict(highschooldict,doc[0].get_text().strip()) # SCHOOL TYPE\n",
    "    state=getFromDict(states_dict,doc[1].get_text().strip()) # save the state of the student\n",
    "    values['international'] = 1 if state=='Other' else -1 # INTERNATIONAL indicator\n",
    "    values['GPA'] = float(doc[3].get_text()) # unweighted GPA\n",
    "    values['GPA_w'] = float(doc[4].get_text()) if doc[4].get_text().strip()!='' else None # Weighted GPA\n",
    "    # Next, we go to the test score box which includes SAT, ACT and AP info\n",
    "    values['admissionstest'] = getAdmissionTestScore(soup.find(\"div\", {\"class\": \"testscorewrap\"}).find_all(\"td\")) #Admissions test\n",
    "    values['SATsubject'] = len(soup.find(\"caption\",text=\"SAT Subject Test Scores\").next_sibling.next_sibling.find_all(\"tr\")) # Number of SAT SUBJECT\n",
    "    ap_num = len(soup.find(\"caption\",text=\"AP Examinations\").next_sibling.next_sibling.find_all(\"tr\")) # Number of AP's \n",
    "    values['AP']=ap_num #AP\n",
    "    if ap_num>0:\n",
    "        doc = soup.find(\"caption\",text=\"AP Examinations\").next_sibling.next_sibling.find_all(\"td\")\n",
    "        values['averageAP'],values['AP']= getScores(doc,np.mean) # AVERAGE AP score\n",
    "    # Every webpage also has three text fields for any additional information, which we just save in the 'addInfo' column\n",
    "    doc = soup.find_all(\"div\", {\"class\": \"word\"})\n",
    "    doc = [d.get_text().strip() for d in doc]  \n",
    "    values['addInfo']= removePunct(doc[0]+doc[1]+doc[2]) # Additional info\n",
    "    # Next: the colleges applied to and the admission results for the admissions table\n",
    "    doc = soup.find(\"table\", {\"class\": \"collchoice\"})\n",
    "    collegelist = doc.find(\"tbody\").find_all(\"tr\") # every university is a row in a table\n",
    "    for c in collegelist:\n",
    "        uni = c.find(\"th\").find(\"span\").get_text().strip() #get university name\n",
    "        if uni in uni_list: # if the university is one of our 25 universities\n",
    "            unirow = dict(zip(columns_uni,[None for i in range(6)])) #initialize dictionary\n",
    "            unirow['collegeID']=uni_name_dict[uni] # get University ID\n",
    "            doc=c.find_all(\"td\", {\"class\": \"center\"})\n",
    "            unirow['earlyAppl']=booleandict[doc[0].get_text().strip()] # Early Admission indicator\n",
    "            unirow['alumni']=booleandict[doc[1].get_text().strip()] # Alumni/Legacy indicator\n",
    "            if values['sports']==None or values['sports']==0: \n",
    "                values['sports']=booleandict[doc[2].get_text().strip()] # Athlete indicator\n",
    "            doc = doc[2].next_sibling.find_next(\"span\")\n",
    "            unirow['acceptStatus']=getFromDict(statusdict,doc.get_text().strip()) # Admission status indicator\n",
    "            if values['canAfford']==None or values['canAfford']==0:\n",
    "                values['canAfford']=getCanAfford(doc.find_next(\"span\").get_text().strip()) # can Afford indicator\n",
    "            unirow['outofstate']= -1 if state==uni_state_dict[uni] else 1 #compare student state to university state for OUT OF STATE indicator\n",
    "            applications.append(unirow) # add dictionary to list of applications\n",
    "    return values, applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to do the real work. We create 3 dataframes:\n",
    "- `students` is a dataframe that will contain all student information. \n",
    "- `colleges` is a dataframe with 25 rows: one for each university. It is hardcoded in `TIdatabase.py`. \n",
    "- `applForm` is a dataframe to combine a student's application with the university to which they are applying. \n",
    "\n",
    "We create a url from every profile name in the list that we obtained earlier and use Beautiful Soup and `requests` to get the webpage html. We use the above defined function to extract all information needed and add them to the dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDz3k  not Found\n",
      "CPU times: user 11min 52s, sys: 37.8 s, total: 12min 30s\n",
      "Wall time: 1h 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove old dataframes if they still exists\n",
    "if ('students' in locals()): \n",
    "    students.cleanup()\n",
    "    del students\n",
    "if ('applForm' in locals()): del applForm\n",
    "# initialize new dataframes\n",
    "students=ti.Student()\n",
    "colleges = ti.College()\n",
    "applForm = ti.ApplForm()\n",
    "for p in r.profileList: # For each profile name\n",
    "    profile_url=baseurl+student_url+p # create url\n",
    "    soup=BeautifulSoup(requests.get(profile_url).text,'html.parser') #get html\n",
    "    # Check for empty webpage\n",
    "    if soup.find(\"div\", {\"class\": \"academicswrap\"})==None: \n",
    "        print p, ' not Found'\n",
    "        continue\n",
    "    # Get information\n",
    "    newrow, applications = getColumnValues(soup)\n",
    "    # insert student information to students dataframe. This generates a new student ID string\n",
    "    studentID=students.insert(newrow)\n",
    "    for app in applications:\n",
    "        # add the newly obtained student ID to the applications dictionaries\n",
    "        app['studentID']=studentID[0]\n",
    "    # add the applications dictionaries to the applForm dataframe\n",
    "    applForm.insert(applications)\n",
    "students.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a database of 5025 students and 16094 applications. Note it is 1 less than before running the cell above, because the profile page for student `EDz3k` was incomplete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5025, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16094, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applForm.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the frames to csv files so they can be used in our classification notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "students.save('collegedata_students.csv')\n",
    "applForm.save('collegedata_applications.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test, we read these csv files to see if the dataframes are still correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentID</th>\n",
       "      <th>classrank</th>\n",
       "      <th>admissionstest</th>\n",
       "      <th>AP</th>\n",
       "      <th>averageAP</th>\n",
       "      <th>SATsubject</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GPA_w</th>\n",
       "      <th>program</th>\n",
       "      <th>schooltype</th>\n",
       "      <th>intendedgradyear</th>\n",
       "      <th>addInfo</th>\n",
       "      <th>canAfford</th>\n",
       "      <th>female</th>\n",
       "      <th>MinorityGender</th>\n",
       "      <th>MinorityRace</th>\n",
       "      <th>international</th>\n",
       "      <th>firstinfamily</th>\n",
       "      <th>sports</th>\n",
       "      <th>artist</th>\n",
       "      <th>workexp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S50C3UECT8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2290</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.34</td>\n",
       "      <td>Biomedical engineering</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Basketball outside of school violin cancer awa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2080</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Swimming 3 years Water Polo 3 years Foreign La...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ZRH2MVO4F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2200</td>\n",
       "      <td>6</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>Pre Med</td>\n",
       "      <td>-1</td>\n",
       "      <td>2012</td>\n",
       "      <td>City Government Youth Partnership Advisory Com...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3I94MHBBCL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2210</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIO07T1RL7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2040</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>-1</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    studentID  classrank  admissionstest  AP  averageAP  SATsubject   GPA  GPA_w                 program  schooltype  intendedgradyear                                            addInfo  canAfford  female  MinorityGender  MinorityRace  international  firstinfamily  sports  artist  workexp\n",
       "0  S50C3UECT8        NaN            2290   7   5.000000           3  3.80   4.34  Biomedical engineering          -1              2017  Basketball outside of school violin cancer awa...          0       1              -1            -1             -1            NaN      -1     NaN      NaN\n",
       "0  JTEQOV7ZCB        NaN            2080   5   4.400000           4  3.90   4.22  Mechanical Engineering           1              2018  Swimming 3 years Water Polo 3 years Foreign La...          1       1              -1            -1             -1            NaN      -1     NaN      NaN\n",
       "0  5ZRH2MVO4F        NaN            2200   6   4.833333           3  4.00   4.58                 Pre Med          -1              2012  City Government Youth Partnership Advisory Com...          0      -1              -1            -1             -1            NaN      -1     NaN      NaN\n",
       "0  3I94MHBBCL        NaN            2210   4   4.250000           0  3.72    NaN                     NaN          -1              2014                                                NaN          0       1              -1            -1             -1            NaN      -1     NaN      NaN\n",
       "0  EIO07T1RL7        NaN            2040   6   4.000000           0  3.88    NaN                 English          -1              2018                                                NaN          1      -1              -1            -1             -1            NaN      -1     NaN      NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ('students' in locals()): \n",
    "    students.cleanup()\n",
    "    del students\n",
    "if ('applForm' in locals()): del applForm\n",
    "students=ti.Student()\n",
    "applForm = ti.ApplForm()\n",
    "students.read('collegedata_students.csv')\n",
    "applForm.read('collegedata_applications.csv')\n",
    "students.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentID</th>\n",
       "      <th>collegeID</th>\n",
       "      <th>earlyAppl</th>\n",
       "      <th>visited</th>\n",
       "      <th>alumni</th>\n",
       "      <th>outofstate</th>\n",
       "      <th>acceptStatus</th>\n",
       "      <th>acceptProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S50C3UECT8</td>\n",
       "      <td>Rice</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>UPenn</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JTEQOV7ZCB</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    studentID  collegeID  earlyAppl  visited  alumni  outofstate  acceptStatus  acceptProb\n",
       "0  S50C3UECT8       Rice         -1      NaN      -1          -1             1         NaN\n",
       "0  JTEQOV7ZCB      UPenn         -1      NaN      -1           1            -1         NaN\n",
       "1  JTEQOV7ZCB  Princeton         -1      NaN      -1           1            -1         NaN\n",
       "2  JTEQOV7ZCB    Harvard          1      NaN      -1           1            -1         NaN\n",
       "3  JTEQOV7ZCB   Stanford         -1      NaN      -1          -1            -1         NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applForm.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have succesfully scraped admissions data from collegedata.com. The results can be found in `collegedata_students.csv` and `collegedata_applications.csv`. Next, we normalize the data in `normalize.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
